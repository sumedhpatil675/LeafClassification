{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImagesPreprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LkwRQa-8WYv"
      },
      "source": [
        "In this notebook we will do image preprocessing,features extraction and features selections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECM6wEwd8qo6"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vnkOZ5l8x3h",
        "outputId": "dc8bc0a3-4b86-4490-b798-2ef8253dc23d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njSES4F68xyy"
      },
      "source": [
        "##Code To Convert images data into numpy array\n",
        "\n",
        "dir = '/content/drive/MyDrive/FinalYear_Project/DATASET_for_ML/swedish_ml/'\n",
        "categories = ['Acer','Alnus incana','Betula pubescens','Fagus silvatica','Populus','Populus tremula','Quercus','Salix alba','Salix aurita','Salix sinerea','Sorbus aucuparia','Sorbus intermedia','Tilia','Ulmus carpinifolia','Ulmus glabra']\n",
        "data = []\n",
        "\n",
        "for category in categories:\n",
        "  path = os.path.join(dir,category)\n",
        "  label = categories.index(category)\n",
        "\n",
        "  for img in os.listdir(path):\n",
        "    imgpath = os.path.join(path,img)\n",
        "    leaf_img = cv2.imread(imgpath,0)\n",
        "    try:\n",
        "        leaf_img = cv2.resize(leaf_img,(50,50))\n",
        "        #plt.imshow(leaf_img)\n",
        "        image = np.array(leaf_img).flatten()\n",
        "        data.append([image,label])\n",
        "    except Exception as e:\n",
        "        pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odo-9UTH8xng"
      },
      "source": [
        "##Seperating features and labels\n",
        "import random\n",
        "random.shuffle(data)\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for feature,label in data:\n",
        "  features.append(feature)\n",
        "  labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qITsELhn9Uw-"
      },
      "source": [
        "#normalizing the data\n",
        "features = np.array(features)\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "features = min_max_scaler.fit_transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAwyApZY9UrV"
      },
      "source": [
        "###Applying PCA technique to extract best features\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=10,svd_solver='full')  # project from 64 to 2 dimensions\n",
        "reduced_features = pca.fit_transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-r25CY9Al7z"
      },
      "source": [
        "num_rows, num_cols = reduced_features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv-hRynD9Uo1"
      },
      "source": [
        "reduced_data = []\n",
        "for i in range(num_rows):\n",
        "  reduced_data.append([reduced_features[i],labels[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Ue29F59UmJ"
      },
      "source": [
        "reduced_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSKTYHxdAx8i"
      },
      "source": [
        "##Saving reduced and normalized features\n",
        "##Saving data to pickle file\n",
        "pick_in = open('/content/drive/MyDrive/FinalYear_Project/pickles_dataset/swedishReduced.pickle','wb')\n",
        "pickle.dump(reduced_data,pick_in)\n",
        "pick_in.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}